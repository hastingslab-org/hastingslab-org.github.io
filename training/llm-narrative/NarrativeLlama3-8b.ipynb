{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c",
   "metadata": {
    "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c"
   },
   "source": [
    "# Working with Narrative Data\n",
    "\n",
    "This notebook illustrates some examples of working with narrative text data using small, local language models.\n",
    "\n",
    "## Running this notebook on a newer MacBook with Apple Silicon Chip\n",
    "\n",
    "You will need an environment with Python and Jupyter installed. To create an environment with Anaconda for Python 3.12, execute: \n",
    "\n",
    "```\n",
    "conda create --name llm-narrative python=3.12\n",
    "conda activate llm-narrative\n",
    "conda install jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Running this notebook on older MacBooks or any other machine\n",
    "\n",
    "Please run this script on [Google Colab](https://colab.research.google.com/). After opening the notebook there, please change the settings to using a GPU, check [here](https://www.geeksforgeeks.org/how-to-use-gpu-in-google-colab/) for instructions on how to do that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2",
   "metadata": {
    "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2"
   },
   "source": [
    "### Install required libraries\n",
    "\n",
    "For the newer MacBooks with Apple Chips we will use `mlx-lm` to load a small, quantized version of the Llama 3 8b instruct model, so that it can run on a single laptop (https://ollama.com/library/llama3). For older MacBooks and other machines we will use a quantized version of the model provided by the hugging face community (https://huggingface.co/astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit).\n",
    "\n",
    "Depending on the machine, different packages are required and will be installed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
    "outputId": "bdbaad62-1046-41f0-d7e9-2737146ef73c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: transformers in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (4.41.2)\n",
      "Requirement already satisfied: optimum in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (1.20.0)\n",
      "Requirement already satisfied: accelerate in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (0.31.0)\n",
      "Requirement already satisfied: auto-gptq in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (0.2.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: filelock in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: coloredlogs in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: datasets in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from optimum) (2.20.0)\n",
      "Requirement already satisfied: psutil in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: rouge in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from auto-gptq) (1.0.1)\n",
      "Collecting scipy (from bitsandbytes)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (5.27.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: six in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from pandas->datasets->optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ctumes/miniforge3/envs/llm-narrative/lib/python3.12/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp312-cp312-macosx_12_0_arm64.whl (29.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0 scipy-1.14.0\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# for the newer MacBooks with the Apple Chip\n",
    "# changed for testing but change back later\n",
    "if platform.processor() != 'arm':\n",
    "    ! pip install mlx-lm torch transformers\n",
    "# for all other machines\n",
    "else:\n",
    "    ! pip install torch transformers optimum accelerate auto-gptq bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f",
   "metadata": {
    "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f"
   },
   "source": [
    "### Install Llama 3 - 8b\n",
    "Next we install the quantized version of the Llama 8b language model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bac8054-5e69-432b-9b8e-9372b69084ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "1bac8054-5e69-432b-9b8e-9372b69084ac",
    "outputId": "5b40de9a-b209-4cc3-f203-edfc42f8f35f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need optimum > 1.13.2 and auto-gptq > 0.4.2 . Make sure to have that version installed - detected version : optimum 1.20.0 and autogptq 0.2.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m config\u001b[38;5;241m.\u001b[39mquantization_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_exllama\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m config\u001b[38;5;241m.\u001b[39mquantization_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexllama_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# low_cpu_mem_usage=True,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# load_in_4bit=True,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/modeling_utils.py:3192\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_quantized \u001b[38;5;129;01mor\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_quantized:\n\u001b[0;32m-> 3192\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoHfQuantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_quantization_configs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[1;32m   3194\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3196\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m quantization_config\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/quantizers/auto.py:157\u001b[0m, in \u001b[0;36mAutoHfQuantizer.merge_quantization_configs\u001b[0;34m(cls, quantization_config, quantization_config_from_args)\u001b[0m\n\u001b[1;32m    154\u001b[0m     warning_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quantization_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     quantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoQuantizationConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quantization_config, (GPTQConfig, AwqConfig)) \u001b[38;5;129;01mand\u001b[39;00m quantization_config_from_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# special case for GPTQ / AWQ config collision\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     loading_attr_dict \u001b[38;5;241m=\u001b[39m quantization_config_from_args\u001b[38;5;241m.\u001b[39mget_loading_attributes()\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/quantizers/auto.py:87\u001b[0m, in \u001b[0;36mAutoQuantizationConfig.from_dict\u001b[0;34m(cls, quantization_config_dict)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown quantization type, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - supported types are:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(AUTO_QUANTIZER_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     86\u001b[0m target_cls \u001b[38;5;241m=\u001b[39m AUTO_QUANTIZATION_CONFIG_MAPPING[quant_method]\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/utils/quantization_config.py:96\u001b[0m, in \u001b[0;36mQuantizationConfigMixin.from_dict\u001b[0;34m(cls, config_dict, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config_dict, return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    Instantiates a [`QuantizationConfigMixin`] from a Python dictionary of parameters.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        [`QuantizationConfigMixin`]: The configuration object instantiated from those parameters.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     to_remove \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/utils/quantization_config.py:631\u001b[0m, in \u001b[0;36mGPTQConfig.__init__\u001b[0;34m(self, bits, tokenizer, dataset, group_size, damp_percent, desc_act, sym, true_sequential, use_cuda_fp16, model_seqlen, block_name_to_quantize, module_name_preceding_first_block, batch_size, pad_token_id, use_exllama, max_input_length, exllama_config, cache_block_outputs, modules_in_block_to_quantize, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_block_outputs \u001b[38;5;241m=\u001b[39m cache_block_outputs\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_in_block_to_quantize \u001b[38;5;241m=\u001b[39m modules_in_block_to_quantize\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llm-narrative/lib/python3.12/site-packages/transformers/utils/quantization_config.py:698\u001b[0m, in \u001b[0;36mGPTQConfig.post_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m         autogptq_version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_gptq\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m optimum_version \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.13.2\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m autogptq_version \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.4.2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 698\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need optimum > 1.13.2 and auto-gptq > 0.4.2 . Make sure to have that version installed - detected version : optimum \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimum_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and autogptq \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautogptq_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m             )\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_in_block_to_quantize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     optimum_version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimum\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: You need optimum > 1.13.2 and auto-gptq > 0.4.2 . Make sure to have that version installed - detected version : optimum 1.20.0 and autogptq 0.2.0"
     ]
    }
   ],
   "source": [
    "if platform.processor() != 'arm':\n",
    "    from mlx_lm import load, generate\n",
    "    model, tokenizer = load(\"mlx-community/Meta-Llama-3-8B-Instruct-4bit\")\n",
    "else:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "    import torch\n",
    "\n",
    "    MODEL_ID=\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\")\n",
    "\n",
    "    config = AutoConfig.from_pretrained(MODEL_ID)\n",
    "    config.quantization_config[\"disable_exllama\"] = False\n",
    "    config.quantization_config[\"exllama_config\"] = {\"version\":2}\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID, \n",
    "            device_map='auto', \n",
    "            torch_dtype=torch.bfloat16, \n",
    "            trust_remote_code=True, \n",
    "            # low_cpu_mem_usage=True,\n",
    "            # load_in_4bit=True,\n",
    "            config=config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b151146-c274-458d-a844-343aaf7977d5",
   "metadata": {
    "id": "1b151146-c274-458d-a844-343aaf7977d5"
   },
   "source": [
    "### Running the model with an example prompt\n",
    "\n",
    "We show that the model can run with an example prompt. First we define the system prompt, which tells the model what character to adopt. Then we give it an instruction to introduce itself. Again, depending on the machine and therefore model used, we use slightly different functions to generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
    "outputId": "1948ffb3-27e8-42e7-858c-f8f109f90e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! My name is Ada, and I'm a helpful chatbot assistant. I'm here to assist you with any questions or tasks you may have. I'm a large language model, trained on a vast amount of text data, which enables me to understand and respond to natural language inputs.\\n\\nI'm designed to be friendly, approachable, and knowledgeable. I can help you with a wide range of topics, from general knowledge and entertainment to more specific areas like science, technology, and health....\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from IPython.display import display\n",
    "\n",
    "SYSTEM_MSG = \"You are a helpful chatbot assistant.\"\n",
    "\n",
    "def generateFromPrompt(promptStr,maxTokens=100):\n",
    "    if platform.processor() == 'arm':\n",
    "      messages = [ {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "              {\"role\": \"user\", \"content\": promptStr}, ]\n",
    "      input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "      prompt = tokenizer.decode(input_ids)\n",
    "      response = generate(model, tokenizer, prompt=prompt,max_tokens=maxTokens)\n",
    "    else:\n",
    "      message = [{\"role\": \"user\", \"content\": promptStr},]\n",
    "      pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,max_new_tokens=maxTokens)\n",
    "      result = pipe(message)\n",
    "      response = result[0]['generated_text'][1]['content']\n",
    "    return(response)\n",
    "\n",
    "\n",
    "response = generateFromPrompt(\"Please introduce yourself\")\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97bc9ea-8528-4591-b30d-a653a7a863c7",
   "metadata": {
    "id": "d97bc9ea-8528-4591-b30d-a653a7a863c7"
   },
   "source": [
    "Now we illustrate performance on a slightly more medically themed topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac53b7a6-f0ea-4597-9550-194dccdc1829",
   "metadata": {
    "id": "ac53b7a6-f0ea-4597-9550-194dccdc1829",
    "outputId": "81327048-4d70-444e-da79-4cdc425aa392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help! Allergies can cause a wide range of symptoms, but here are some common ones:\n",
      "\n",
      "1. **Congestion and stuffiness**: Nasal passages may become inflamed, leading to a runny nose, stuffy nose, and difficulty breathing.\n",
      "2. **Itchy, watery eyes**: Allergens can irritate the eyes, causing itchiness, redness, and excessive tearing.\n",
      "3. **Sneezing and coughing**: Irritation in the nasal passages and throat can lead to sneezing and coughing.\n",
      "4. **Skin rashes and hives**: Allergic reactions can cause skin irritation, leading to redness, itching, and hives (wheals and red bumps).\n",
      "5. **Stomach cramps and diarrhea**: In some cases, food allergies can cause stomach cramps, diarrhea, and vomiting.\n",
      "6. **Respiratory issues**: Allergies can exacerbate conditions like asthma, leading to...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please tell me some symptoms of allergies\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1f671-353f-450a-a45a-0f5f18e241d1",
   "metadata": {
    "id": "c3f1f671-353f-450a-a45a-0f5f18e241d1"
   },
   "source": [
    "### Using the model to extract themes from narrative texts\n",
    "\n",
    "Here we demonstrate how the model can be used to extract themes from a narrative interview text.\n",
    "\n",
    "This brief interview extract comes from the article Price, T., McColl, E., & Visram, S. (2022). Barriers and facilitators of childhood flu vaccination: The views of parents in North East England. Zeitschrift Fur Gesundheitswissenschaften = Journal of Public Health, 30(11), 2619–2626. https://doi.org/10.1007/s10389-022-01695-2\n",
    "\n",
    "```\n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "747d6507-1895-4ba6-b793-560610e4f015",
   "metadata": {
    "id": "747d6507-1895-4ba6-b793-560610e4f015",
    "outputId": "8336d52a-14ae-4ca7-ce92-4de956d1300e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on this interview transcript, some themes that can be identified are:\n",
      "\n",
      "1. **Perception of flu as a serious issue**: The participant views flu as a serious issue, especially for certain at-risk groups such as the elderly, young, and those with long-term conditions.\n",
      "2. **Importance of vaccination**: The participant has always been in favor of the flu vaccination campaign and has received the jab themselves as a healthcare worker. They also mention the benefits of vaccination in protecting vulnerable people, including children and those they come into contact with.\n",
      "3. **Personal experience with flu-like symptoms**: The participant has had a limited experience with flu-like symptoms, which they describe as fever, nausea, muscle aches, and high temperature.\n",
      "4. **Awareness of healthcare system strains**: The participant is aware of the strains on the healthcare system, which they believe could make the flu situation worse.\n",
      "5. **Importance of protecting vulnerable groups**: The participant emphasizes the importance of protecting vulnerable groups, such as...\n"
     ]
    }
   ],
   "source": [
    "interviewExtract = \"\"\"\n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\"\"\"\n",
    "\n",
    "response = generateFromPrompt(\"Please identify some themes in the following interview transcript: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c131359e-0187-4e58-8996-4d50e2b18555",
   "metadata": {
    "id": "c131359e-0187-4e58-8996-4d50e2b18555"
   },
   "source": [
    "### Exploring structural aspects of the interview text\n",
    "\n",
    "We can also try to use the LM to extract structural aspects of the interview speech such as how confident the speaker is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e93aaa5-6562-4eb8-a906-b33bb1705d79",
   "metadata": {
    "id": "7e93aaa5-6562-4eb8-a906-b33bb1705d79",
    "outputId": "963a44fd-6e93-4ac1-f295-1a422e6260db",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the interviewee's responses, I would rate their confidence as moderate to high. Here's why:\n",
      "\n",
      "* They provide clear and concise answers to the questions, demonstrating a good understanding of the topic.\n",
      "* They use technical terms such as \"strains on the healthcare system\" and \"herd immunity\", which suggests they have a good grasp of the subject matter.\n",
      "* They also provide personal experiences and anecdotes, such as having had a flu jab and having had a bad case of flu in the past, which adds credibility to their responses.\n",
      "* They are able to articulate their thoughts and opinions clearly, using phrases such as \"I think\", \"I'm certainly aware\", and \"I always had a flu jab\", which suggests they are confident in their views.\n",
      "* However, there are a few moments where they seem to hesitate or pause, such as when they say \"I think I possibly only had flu once in my life\" or \"I think from a symptoms point of view it was just...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please describe how confident the interviewee is in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "display(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b40dea-6f28-42fe-a01c-f25e1835848b",
   "metadata": {
    "id": "59b40dea-6f28-42fe-a01c-f25e1835848b"
   },
   "source": [
    "### Exploring emotional aspects of the interview text\n",
    "\n",
    "We can explore any emotional dimensions that are present in the narrative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821be237-4621-4bad-9910-dd3ad7f5ce7c",
   "metadata": {
    "id": "821be237-4621-4bad-9910-dd3ad7f5ce7c",
    "outputId": "e9991062-cfd6-4668-b3b3-e62264da99d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment expressed by Participant 12 in this interview is one of awareness and concern about the seriousness of flu, particularly for vulnerable groups such as the elderly, young, and those with long-term conditions. They also express a sense of responsibility and motivation to take action to protect themselves and others, as evident in their decision to get the flu jab and their support for the screening program.\n",
      "\n",
      "The emotions expressed by Participant 12 are likely to be a mix of concern, responsibility, and motivation. They seem to be aware of the potential risks and consequences of flu, particularly for vulnerable groups, and are motivated to take action to protect themselves and others. They also express a sense of responsibility as a healthcare worker and public health worker to take steps to prevent the spread of flu.\n",
      "\n",
      "The tone of the interview is informative, with Participant 12 providing their thoughts and experiences about flu. They seem to be speaking from a place of knowledge and expertise, having studied and worked in the field of public health. The language used...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please describe the sentiment and any emotions of the interviewee in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bcbcd-8122-4163-95f1-c5b8d82d20db",
   "metadata": {
    "id": "5f3bcbcd-8122-4163-95f1-c5b8d82d20db"
   },
   "source": [
    "### Extracting information according to a predefined schema\n",
    "\n",
    "The original study from which this transcript has been sourced harnessed the COM-B theory of behaviour change to frame the research study into perspectives on childhood vaccination. We can similarly use the language model to extract examples of those theoretical elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2a38602-d521-4fff-b5dc-d9dea1e992fd",
   "metadata": {
    "id": "d2a38602-d521-4fff-b5dc-d9dea1e992fd",
    "outputId": "d88ddaa4-c9d5-4a12-849f-293a1050de7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the examples of COM-B (capability, opportunity, and motivation) elements extracted from the interview:\n",
      "\n",
      "**Capability:**\n",
      "\n",
      "* \"I think I possibly only had flu once in my life and it may have just been a really bad bug.\" (indicates that the participant has some knowledge about flu, but not extensive)\n",
      "* \"I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah.\" (shows that the participant has some understanding of the symptoms of flu)\n",
      "\n",
      "**Opportunity:**\n",
      "\n",
      "* \"I know a little bit from my yeah, kind of studies and from work, etc.\" (indicates that the participant has had opportunities to learn about flu through their studies and work)\n",
      "* \"We get provided with that as healthcare workers and as public health workers through our employer.\" (shows that the participant has opportunities to receive flu jabs as part of their job)\n",
      "\n",
      "**Motivation:**\n",
      "\n",
      "* \"I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular.\" (indicates that the participant is motivated to take action to protect vulnerable groups)\n",
      "* \"I always had a flu jab myself.\" (shows that the participant is motivated to take personal action to protect themselves)\n",
      "* \"I think, you know, we see the benefits to, to our children as well in terms of protecting them.\" (indicates that the participant is motivated to take action to protect their children)\n",
      "* \"But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well.\" (shows that the participant is motivated to take action to protect vulnerable people in their community)\n",
      "\n",
      "Note that these examples are not exhaustive, and the participant may have mentioned other COM-B elements that are not included here....\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please extract examples of COM-B (capability, opportunity, and motivation) elements in the following interview: ' \"+interviewExtract+\"'\",maxTokens=400)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7837b1-7166-4d2a-9639-9377289a0af3",
   "metadata": {
    "id": "4d7837b1-7166-4d2a-9639-9377289a0af3"
   },
   "source": [
    "## Exercise: Do it yourself!\n",
    "\n",
    "1. Choose an extract of text from an openly available source of interview text, narrative or transcripts. Some examples that you might find useful include:\n",
    "    - Medical Transcription examples: https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions/data\n",
    "\n",
    "\n",
    "\n",
    "2. Use the LM to extract information from the text.\n",
    "    - Themes\n",
    "    - Structural aspects\n",
    "    - Emotional aspects\n",
    "    - Extract some formal, structured information such as disease / diagnosis"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
