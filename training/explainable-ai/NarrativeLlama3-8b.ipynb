{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c",
   "metadata": {},
   "source": [
    "# Working with Narrative Data\n",
    "\n",
    "This notebook illustrates some examples of working with narrative text data using small, local language models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2",
   "metadata": {},
   "source": [
    "### Install required libraries \n",
    "\n",
    "For Apple we will use `mlx-lm` to load a small, quantized version of the Llama 3 8b instruct model, so that it can run on a single laptop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlx-lm\n",
      "  Downloading mlx_lm-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting mlx>=0.14.1 (from mlx-lm)\n",
      "  Downloading mlx-0.15.1-cp312-cp312-macosx_13_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting numpy (from mlx-lm)\n",
      "  Downloading numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m880.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.39.3 (from mlx-lm)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf (from mlx-lm)\n",
      "  Downloading protobuf-5.27.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from mlx-lm) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from mlx-lm) (3.1.4)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers>=4.39.3->mlx-lm)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (23.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.39.3->mlx-lm)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (2.32.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.39.3->mlx-lm)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.39.3->mlx-lm)\n",
      "  Downloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers>=4.39.3->mlx-lm)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from jinja2->mlx-lm) (2.1.3)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/training-ai/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2024.6.2)\n",
      "Downloading mlx_lm-0.14.3-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m694.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:02\u001b[0m0m\n",
      "\u001b[?25hDownloading mlx-0.15.1-cp312-cp312-macosx_13_0_arm64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading protobuf-5.27.1-cp38-abi3-macosx_10_9_universal2.whl (412 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.5/278.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tqdm, sympy, safetensors, regex, protobuf, numpy, networkx, mlx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers, mlx-lm\n",
      "Successfully installed filelock-3.15.1 fsspec-2024.6.0 huggingface-hub-0.23.4 mlx-0.15.1 mlx-lm-0.14.3 mpmath-1.3.0 networkx-3.3 numpy-2.0.0 protobuf-5.27.1 regex-2024.5.15 safetensors-0.4.3 sympy-1.12.1 tokenizers-0.19.1 torch-2.3.1 tqdm-4.66.4 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "! pip install mlx-lm torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f",
   "metadata": {},
   "source": [
    "### Install Llama 3 - 8b \n",
    "Next we install the quantized version of the Llama 8b language model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bac8054-5e69-432b-9b8e-9372b69084ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e0eb243dbb45e7ad5f6ea90ddd621e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6554dc6f7d48fc819bc70afa738576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752404950c2b4feabc4017bc58e69928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/52.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235f9b02d9d6411e9df2ad71461d9bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec38d07a70845398c9e16376e56c6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c259314b58f4d18ac4554acc35b0629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfd53a58e6f437ca99b70e37a50623c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "model, tokenizer = load(\"mlx-community/Meta-Llama-3-8B-Instruct-4bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b151146-c274-458d-a844-343aaf7977d5",
   "metadata": {},
   "source": [
    "### Running the model with an example prompt\n",
    "\n",
    "We show that the model can run with an example prompt. First we define the system prompt, which tells the model what character to adopt. Then we give it an instruction to introduce itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I'm ChatGenesis, your friendly and helpful chatbot. I'm here to assist you with any questions or topics you'd like to discuss. I'm a large language model, trained on a vast amount of text data, which enables me to understand and respond to your queries in a human-like way.\n",
      "\n",
      "I'm constantly learning and improving, so please bear with me if I make any mistakes. My goal is to provide you with accurate and helpful information, and to make our conversation as...\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG = \"You are a helpful chatbot assistant.\"\n",
    "\n",
    "def generateFromPrompt(promptStr,maxTokens=100): \n",
    "    messages = [ {\"role\": \"system\", \"content\": SYSTEM_MSG}, \n",
    "             {\"role\": \"user\", \"content\": promptStr}, ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    prompt = tokenizer.decode(input_ids)\n",
    "    response = generate(model, tokenizer, prompt=prompt,max_tokens=maxTokens)\n",
    "    return(response)\n",
    "\n",
    "response = generateFromPrompt(\"Please introduce yourself\")\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97bc9ea-8528-4591-b30d-a653a7a863c7",
   "metadata": {},
   "source": [
    "Now we illustrate performance on a slightly more medically themed topic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac53b7a6-f0ea-4597-9550-194dccdc1829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help! Allergies can cause a wide range of symptoms, but here are some common ones:\n",
      "\n",
      "1. **Congestion and stuffiness**: Nasal passages may become inflamed, leading to a runny nose, stuffy nose, and difficulty breathing.\n",
      "2. **Itchy, watery eyes**: Allergens can irritate the eyes, causing itchiness, redness, and excessive tearing.\n",
      "3. **Sneezing and coughing**: Irritation in the nasal passages and throat can lead to sneezing and coughing.\n",
      "4. **Skin rashes**: Allergic reactions can cause skin rashes, hives, or eczema-like symptoms.\n",
      "5. **Hives**: Red, itchy, and swollen patches on the skin, often accompanied by itching.\n",
      "6. **Anaphylaxis**: A severe, life-threatening allergic reaction that can cause difficulty breathing, rapid heartbeat, and a drop in blood pressure. This requires immediate medical...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please tell me some symptoms of allergies\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1f671-353f-450a-a45a-0f5f18e241d1",
   "metadata": {},
   "source": [
    "### Using the model to extract themes from narrative texts\n",
    "\n",
    "Here we demonstrate how the model can be used to extract themes from a narrative interview text. \n",
    "\n",
    "This brief interview extract comes from the article Price, T., McColl, E., & Visram, S. (2022). Barriers and facilitators of childhood flu vaccination: The views of parents in North East England. Zeitschrift Fur Gesundheitswissenschaften = Journal of Public Health, 30(11), 2619–2626. https://doi.org/10.1007/s10389-022-01695-2\n",
    "\n",
    "```\n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747d6507-1895-4ba6-b793-560610e4f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on this interview transcript, some themes that can be identified are:\n",
      "\n",
      "1. **Perception of flu as a serious issue**: The participant views flu as a serious issue, especially for certain at-risk groups such as the elderly, young, and those with long-term conditions.\n",
      "2. **Importance of vaccination**: The participant has always been in favor of the flu vaccination campaign and has received the jab themselves as a healthcare worker. They also mention the benefits of vaccination in protecting vulnerable people, including children and those they come into contact with.\n",
      "3. **Personal experience with flu-like symptoms**: The participant has had a limited experience with flu-like symptoms, which they describe as fever, nausea, muscle aches, and high temperature.\n",
      "4. **Awareness of healthcare system strains**: The participant is aware of the strains on the healthcare system, which they believe could make the flu situation worse.\n",
      "5. **Importance of screening programs**: The participant mentions the importance of screening programs in protecting at-risk groups...\n"
     ]
    }
   ],
   "source": [
    "interviewExtract = \"\"\" \n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\"\"\"\n",
    "\n",
    "response = generateFromPrompt(\"Please identify some themes in the following interview transcript: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c131359e-0187-4e58-8996-4d50e2b18555",
   "metadata": {},
   "source": [
    "### Exploring structural aspects of the interview text\n",
    "\n",
    "We can also try to use the LM to extract structural aspects of the interview speech such as how confident the speaker is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e93aaa5-6562-4eb8-a906-b33bb1705d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the interviewee's responses, I would rate their confidence as moderate to high. Here's why:\n",
      "\n",
      "* They provide clear and concise answers to the questions, demonstrating a good understanding of the topic.\n",
      "* They use technical terms such as \"strains on the healthcare system\" and \"herd immunity\", which suggests they have a good grasp of the subject matter.\n",
      "* They share their personal experience of having had flu-like symptoms, which adds a level of authenticity to their responses.\n",
      "* They also mention that they have received the flu jab as a healthcare worker, which shows that they are familiar with the measures taken to prevent the spread of flu.\n",
      "\n",
      "However, there are a few moments where their confidence wavers:\n",
      "\n",
      "* They start their response by saying \"Yeah, so I know a little bit from my yeah, kind of studies and from work, etc.\", which suggests that they may not be entirely confident in their knowledge.\n",
      "* They use phrases such as \"I think\" and \"I believe\"...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please describe how confident the interviewee is in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b40dea-6f28-42fe-a01c-f25e1835848b",
   "metadata": {},
   "source": [
    "### Exploring emotional aspects of the interview text \n",
    "\n",
    "We can explore any emotional dimensions that are present in the narrative text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "821be237-4621-4bad-9910-dd3ad7f5ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment expressed by Participant 12 in this interview is one of caution and concern. They seem to be aware of the seriousness of the flu, particularly for certain at-risk groups, and are motivated to take steps to protect themselves and others. They mention the importance of developing herd immunity and protecting vulnerable individuals, such as the elderly and young children.\n",
      "\n",
      "The emotions expressed by Participant 12 are likely to be a mix of concern, responsibility, and empathy. They are concerned about the potential impact of the flu on vulnerable individuals and are motivated to take action to protect them. They also seem to be responsible and aware of their role in helping to prevent the spread of the flu, as a healthcare worker and public health worker. Additionally, they may be empathetic towards those who are affected by the flu, particularly the elderly and young children who are more vulnerable to its effects.\n",
      "\n",
      "The tone of the interview is calm and matter-of-fact, with Participant 12 providing a clear and informed perspective on the flu....\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please describe the sentiment and any emotions of the interviewee in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bcbcd-8122-4163-95f1-c5b8d82d20db",
   "metadata": {},
   "source": [
    "### Extracting information according to a predefined schema\n",
    "\n",
    "The original study from which this transcript has been sourced harnessed the COM-B theory of behaviour change to frame the research study into perspectives on childhood vaccination. We can similarly use the language model to extract examples of those theoretical elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a38602-d521-4fff-b5dc-d9dea1e992fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the examples of COM-B (capability, opportunity, and motivation) elements extracted from the interview:\n",
      "\n",
      "**Capability:**\n",
      "\n",
      "* \"I think I know a little bit from my studies and from work, etc.\" (indicates that the participant has the capability to understand the seriousness of flu)\n",
      "* \"I always had a flu jab myself\" (indicates that the participant has the capability to take care of their own health)\n",
      "* \"We get provided with that as healthcare workers and as public health workers through our employer\" (indicates that the participant has the capability to access flu vaccination as a healthcare worker)\n",
      "\n",
      "**Opportunity:**\n",
      "\n",
      "* \"I think I possibly only had flu once in my life and it may have just been a really bad bug\" (indicates that the participant has had limited opportunities to experience flu firsthand)\n",
      "* \"I was literally bed bound for it when I was at university for a few, good few days\" (indicates that the participant has had limited opportunities to experience severe symptoms of flu)\n",
      "\n",
      "**Motivation:**\n",
      "\n",
      "* \"I think it is quite a serious issue\" (indicates that the participant is motivated to take the issue of flu seriously)\n",
      "* \"I think I'm certainly aware of the seriousness of it for certain at-risk groups in particular\" (indicates that the participant is motivated to protect vulnerable groups)\n",
      "* \"I always been for the campaign obviously I understand the evidence base behind it\" (indicates that the participant is motivated to support the flu vaccination campaign)\n",
      "* \"I think, you know, we see the benefits to, to our children as well in terms of protecting them\" (indicates that the participant is motivated to protect their own children)\n",
      "* \"But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well\" (indicates that the participant is motivated to protect vulnerable people in their community)\n",
      "\n",
      "Note that these...\n"
     ]
    }
   ],
   "source": [
    "response = generateFromPrompt(\"Please extract examples of COM-B (capability, opportunity, and motivation) elements in the following interview: ' \"+interviewExtract+\"'\",maxTokens=400)\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7837b1-7166-4d2a-9639-9377289a0af3",
   "metadata": {},
   "source": [
    "## Exercise: Do it yourself! \n",
    "\n",
    "1. Choose an extract of text from an openly available source of interview text, narrative or transcripts. Some examples that you might find useful include:\n",
    "    - Medical Transcription examples: https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions/data\n",
    "\n",
    "\n",
    "\n",
    "2. Use the LM to extract information from the text.\n",
    "    - Themes\n",
    "    - Structural aspects\n",
    "    - Emotional aspects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
