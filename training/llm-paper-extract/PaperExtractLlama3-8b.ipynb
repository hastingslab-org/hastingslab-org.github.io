{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c",
   "metadata": {
    "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c"
   },
   "source": [
    "# Extracting information from paper\n",
    "\n",
    "This notebook illustrates some examples of working with text data using small, local language models.\n",
    "\n",
    "## Running this notebook on a newer MacBook with Apple Silicon Chip\n",
    "\n",
    "You will need an environment with Python and Jupyter installed. To create an environment with Anaconda for Python 3.12, execute: \n",
    "\n",
    "```\n",
    "conda create --name llm-narrative python=3.12\n",
    "conda activate llm-narrative\n",
    "conda install jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Running this notebook on older MacBooks or any other machine\n",
    "\n",
    "Please run this script on [Google Colab](https://colab.research.google.com/). After opening the notebook there, please change the settings to using a GPU, check [here](https://www.geeksforgeeks.org/how-to-use-gpu-in-google-colab/) for instructions on how to do that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2",
   "metadata": {
    "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2"
   },
   "source": [
    "### Install required libraries\n",
    "\n",
    "For the newer MacBooks with Apple Chips we will use `mlx-lm` to load a small, quantized version of the Llama 3 8b instruct model, so that it can run on a single laptop (https://ollama.com/library/llama3). For older MacBooks and other machines we will use a quantized version of the model provided by the hugging face community (https://huggingface.co/astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit).\n",
    "\n",
    "Depending on the machine, different packages are required and will be installed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1565aa6e-a6a2-4888-a14d-dc60fb0d89b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
    "outputId": "bdbaad62-1046-41f0-d7e9-2737146ef73c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474db460-415d-4015-9e73-2206fe5bb7d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
    "outputId": "bdbaad62-1046-41f0-d7e9-2737146ef73c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlx-lm in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (0.28.3)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: mlx>=0.29.2 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx-lm) (0.30.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx-lm) (1.26.4)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx-lm) (5.28.3)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx-lm) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx-lm) (3.1.4)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: mlx-metal==0.30.0 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from mlx>=0.29.2->mlx-lm) (0.30.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from jinja2->mlx-lm) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/envs/llms/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# for the newer MacBooks with the Apple Chip\n",
    "# changed for testing but change back later\n",
    "if platform.processor() == 'arm':\n",
    "    ! pip install mlx-lm torch transformers\n",
    "# for all other machines\n",
    "else:\n",
    "    ! pip install torch transformers optimum accelerate auto-gptq bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febb3f0-965a-4af1-ac2c-f9c463592993",
   "metadata": {
    "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f"
   },
   "source": [
    "### Install Model\n",
    "Next we install the quantized version of the selected language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21eaa43b-99fc-4f70-94af-f53d9acd3ef8",
   "metadata": {
    "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419ac938a865428db02d2ae848d71105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if platform.processor() == 'arm':\n",
    "    from mlx_lm import load, generate\n",
    "    model, tokenizer = load ('mlx-community/gemma-3n-E4B-it-lm-4bit') #load(\"mlx-community/Meta-Llama-3-8B-Instruct-4bit\")  # load ('mlx-community/gemma-3n-E4B-it-lm-4bit')\n",
    "else:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "    import torch\n",
    "\n",
    "    MODEL_ID=\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\")\n",
    "\n",
    "    config = AutoConfig.from_pretrained(MODEL_ID)\n",
    "    config.quantization_config[\"disable_exllama\"] = False\n",
    "    config.quantization_config[\"exllama_config\"] = {\"version\":2}\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID, \n",
    "            device_map='auto', \n",
    "            torch_dtype=torch.bfloat16, \n",
    "            trust_remote_code=True, \n",
    "            config=config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b151146-c274-458d-a844-343aaf7977d5",
   "metadata": {
    "id": "1b151146-c274-458d-a844-343aaf7977d5"
   },
   "source": [
    "### Running the model with an example prompt\n",
    "\n",
    "We show that the model can run with an example prompt. First we define the system prompt, which tells the model what character to adopt. Then we give it an instruction to introduce itself. Again, depending on the machine and therefore model used, we use slightly different functions to generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
    "outputId": "1948ffb3-27e8-42e7-858c-f8f109f90e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hello! I am a large language model created by Google DeepMind. I'm an open...\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from IPython.display import display\n",
    "\n",
    "SYSTEM_MSG = \"You are a helpful assistant for processing scientific literature concisely.\"\n",
    "\n",
    "def generateFromPrompt(promptStr,maxTokens=20):\n",
    "    if platform.processor() == 'arm':\n",
    "      messages = [ {\"role\": \"model\", \"content\": SYSTEM_MSG},\n",
    "              {\"role\": \"user\", \"content\": promptStr}, ]\n",
    "      tokenizer.chat_template = \"\"\"\n",
    "{%- for message in messages %}\n",
    "    <start_of_turn> {{-  message['role']\\n + message['content']}} <end_of_turn> \\n\n",
    "{%- endfor %}\n",
    "    <start_of_turn>model \n",
    "\"\"\"\n",
    "      input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "      prompt = tokenizer.decode(input_ids)\n",
    "      response = generate(model, tokenizer, prompt=prompt,max_tokens=maxTokens)\n",
    "    else:\n",
    "      message = [{\"role\": \"user\", \"content\": promptStr},]\n",
    "      pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,max_new_tokens=maxTokens)\n",
    "      result = pipe(message)\n",
    "      response = result[0]['generated_text'][1]['content']\n",
    "    return(response)\n",
    "\n",
    "\n",
    "response = generateFromPrompt(\"Please introduce yourself\")\n",
    "\n",
    "print(response+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929ce85-9df6-48be-a374-1bd6f2bb50e8",
   "metadata": {},
   "source": [
    "###  Now we need the following functions to search the internet for papers. We will use the API OpenAlex for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333800fd-f288-4f9a-a178-449896a02b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse the text \n",
    "def reconstruct_text(inverted_index):\n",
    "    word_index = [] \n",
    "    if inverted_index: \n",
    "        for k,v in inverted_index.items(): \n",
    "            for index in v: \n",
    "                word_index.append([k,index])\n",
    "                \n",
    "        word_index = sorted(word_index,key = lambda x : x[1])\n",
    "        \n",
    "        word_list = []\n",
    "        for i in range(len(word_index)):\n",
    "            word_list.append(word_index[i][0])        \n",
    " \n",
    "        separator = ' ' \n",
    "        reconstructed_text = separator.join(word_list) \n",
    "\n",
    "        return reconstructed_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# function that uses openalex to search web for papers\n",
    "def search_openalex(search_phrase, result_count=10, min_year='2013'):\n",
    "    base_url = \"https://api.openalex.org/works\"  # Replace with the actual API endpoint\n",
    "    \n",
    "    # Create filters\n",
    "    filters = [\n",
    "        \"has_abstract:true\",\n",
    "        \"has_fulltext:true\",\n",
    "        f\"from_publication_date:{min_year}-01-01\"\n",
    "    ]\n",
    "    \n",
    "    # Construct the query parameters\n",
    "    params = {\n",
    "    \"search\": search_phrase,\n",
    "    \"filter\": str.join(\",\", filters),  # Only return works with abstracts\n",
    "    \"per_page\": result_count,  # Limit the search\n",
    "    }\n",
    "    \n",
    "    r = requests.get(base_url, params=params)\n",
    "    res_json = r.json()\n",
    "    \n",
    "    abstract_list = []\n",
    "    for i in range(len(res_json[\"results\"])):\n",
    "        abstract_list.append(reconstruct_text(res_json[\"results\"][i]['abstract_inverted_index']))\n",
    "        \n",
    "    return res_json[\"results\"], abstract_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bcfcb-2a23-4e9f-a23d-da86616aebe5",
   "metadata": {},
   "source": [
    "### Let's try getting papers for our search now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b967c6-45f1-49f2-a6cb-a13c17c629d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your search phrase\n",
    "search_phrase = 'depression randomised controlled trial'\n",
    "# enter how many abstracts you want to receive\n",
    "number_of_abstracts = 10\n",
    "# collect the abstracts\n",
    "res_, abstract = search_openalex(search_phrase, number_of_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e04043-2f35-4cb8-b1c8-4d497d67d7cc",
   "metadata": {},
   "source": [
    "#### Now let's try extracting some information from the abstracts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65abb12-1ed3-4556-a723-01c89c50205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 0 =====\n",
      "Improving Adherence and Clinical Outcomes in Self-Guided Internet Treatment for Anxiety and Depression: Randomised Controlled Trial\n",
      "Australian and New Zealand Clinical Trials Registry ACTRN12610001058066.\n",
      "Population: \n",
      "NONE\n",
      " , intervention: \n",
      "NONE\n",
      " , comparator: \n",
      "NONE\n",
      " , outcome: \n",
      "NONE\n",
      "\n",
      "===== 1 =====\n",
      "Physical exercise and internet-based cognitive–behavioural therapy in the treatment of depression: Randomised controlled trial\n",
      "Background Depression is common and tends to be recurrent. Alternative treatments are needed that are non-stigmatising, accessible and can be prescribed by general medical practitioners. Aims To compare the effectiveness of three interventions for depression: physical exercise, internet-based cognitive–behavioural therapy (ICBT) and treatment as usual (TAU). A secondary aim was to assess changes in self-rated work capacity. Method A total of 946 patients diagnosed with mild to moderate depression were recruited through primary healthcare centres across Sweden and randomly assigned to one of three 12-week interventions (trail registry: KCTR study ID: KT20110063). Patients were reassessed at 3 months (response rate 78%). Results Patients in the exercise and ICBT groups reported larger improvements in depressive symptoms compared with TAU. Work capacity improved over time in all three groups (no significant differences). Conclusions Exercise and ICBT were more effective than TAU by a general medical practitioner, and both represent promising non-stigmatising treatment alternatives for patients with mild to moderate depression.\n",
      "Population: 946 patients diagnosed with mild to moderate depression.\n",
      " , intervention: \n",
      "\n",
      "Physical exercise, internet-based cognitive–behavioural therapy (ICBT), and treatment as usual , comparator: \n",
      "\n",
      "Treatment as usual (TAU)\n",
      " , outcome: \n",
      "\n",
      "Improved depressive symptoms.\n",
      "\n",
      "===== 2 =====\n",
      "A randomised controlled trial of dietary improvement for adults with major depression (the ‘SMILES’ trial)\n",
      "\n",
      "===== 3 =====\n",
      "Chat- and internet-based cognitive–behavioural therapy in treatment of adolescent depression: randomised controlled trial\n",
      "Background Depression is a major contributor to the burden of disease in the adolescent population. Internet-based interventions can increase access to treatment. Aims To evaluate the efficacy of internet-based cognitive–behavioural therapy (iCBT), including therapist chat communication, in treatment of adolescent depression. Method Seventy adolescents, 15–19 years of age and presenting with depressive symptoms, were randomised to iCBT or attention control. The primary outcome was the Beck Depression Inventory II (BDI-II). Results Significant reductions in depressive symptoms were found, favouring iCBT over the control condition (F(1,67) = 6.18, P &lt; 0.05). The between-group effect size was Cohen's d = 0.71 (95% CI 0.22–1.19). A significantly higher proportion of iCBT participants (42.4%) than controls (13.5%) showed a 50% decrease in BDI-II score post-treatment ( P &lt; 0.01). The improvement for the iCBT group was maintained at 6 months. Conclusions The intervention appears to effectively reduce symptoms of depression in adolescents and may be helpful in overcoming barriers to care among young people. Declaration of interest N.T. and G.A. designed the programme. N.T. authored the treatment material. The web platform used for treatment is owned by Linköping University and run on a non-for-profit basis. None of the authors receives any income from the programme.\n",
      "Population: 15–19 year old adolescents presenting with depressive symptoms. , intervention: \n",
      "\n",
      "Internet-based cognitive–behavioural therapy (iCBT), including therapist chat communication.\n",
      " , comparator: \n",
      "Attention control , outcome: \n",
      "\n",
      "Significant reduction in depressive symptoms, favouring iCBT over the control condition.\n",
      "\n",
      "===== 4 =====\n",
      "One-day cognitive–behavioural therapy self-confidence workshops for people with depression: randomised controlled trial\n",
      "Background Despite its high prevalence, help-seeking for depression is low. Aims To assess the effectiveness and cost-effectiveness of 1-day cognitive–behavioural therapy (CBT) self-confidence workshops in reducing depression. Anxiety, self-esteem, prognostic indicators as well as access were also assessed. Method An open randomised controlled trial (RCT) waiting list control design with 12-week follow-up was used (trial registration: ISRCTN26634837). A total of 459 adult participants with depression (Beck Depression Inventory (BDI) scores of 14) self-referred and 382 participants (83%) were followed up. Results At follow-up, experimental and control participants differed significantly on the BDI, with an effect size of 0.55. Anxiety and self-esteem also differed. Of those who participated, 25% were GP non-consulters and 32% were from Black and minority ethnic groups. Women benefited more than men on depression scores. The intervention has a 90% chance of being considered cost-effective if a depression-free day is valued at £14. Conclusions Self-confidence workshops appear promising in terms of clinical effectiveness, cost-effectiveness and access by difficult-to-engage groups.\n",
      "Population: 459 adult participants with depression (Beck Depression Inventory (BDI) scores of 14 , intervention: 1-day cognitive–behavioural therapy (CBT) self-confidence workshops.\n",
      " , comparator: 1-day cognitive–behavioural therapy (CBT) self-confidence workshops vs. waiting list , outcome: \n",
      "\n",
      "Reduced depression (effect size of 0.55).\n",
      "===== 5 =====\n",
      "Effect of exercise for depression: systematic review and network meta-analysis of randomised controlled trials\n",
      "Abstract Objective To identify the optimal dose and modality of exercise for treating major depressive disorder, compared with psychotherapy, antidepressants, and control conditions. Design Systematic review and network meta-analysis. Methods Screening, data extraction, coding, and risk of bias assessment were performed independently and in duplicate. Bayesian arm based, multilevel network meta-analyses were performed for the primary analyses. Quality of the evidence for each arm was graded using the confidence in network meta-analysis (CINeMA) online tool. Data sources Cochrane Library, Medline, Embase, SPORTDiscus, and PsycINFO databases. Eligibility criteria for selecting studies Any randomised trial with exercise arms for participants meeting clinical cut-offs for major depression. Results 218 unique studies with a total of 495 arms and 14 170 participants were included. Compared with active controls (eg, usual care, placebo tablet), moderate reductions in depression were found for walking or jogging (n=1210, κ=51, Hedges’ g −0.62, 95% credible interval −0.80 to −0.45), yoga (n=1047, κ=33, g −0.55, −0.73 to −0.36), strength training (n=643, κ=22, g −0.49, −0.69 to −0.29), mixed aerobic exercises (n=1286, κ=51, g −0.43, −0.61 to −0.24), and tai chi or qigong (n=343, κ=12, g −0.42, −0.65 to −0.21). The effects of exercise were proportional to the intensity prescribed. Strength training and yoga appeared to be the most acceptable modalities. Results appeared robust to publication bias, but only one study met the Cochrane criteria for low risk of bias. As a result, confidence in accordance with CINeMA was low for walking or jogging and very low for other treatments. Conclusions Exercise is an effective treatment for depression, with walking or jogging, yoga, and strength training more effective than other exercises, particularly when intense. Yoga and strength training were well tolerated compared with other treatments. Exercise appeared equally effective for people with and without comorbidities and with different baseline levels of depression. To mitigate expectancy effects, future studies could aim to blind participants and staff. These forms of exercise could be considered alongside psychotherapy and antidepressants as core treatments for depression. Systematic review registration PROSPERO CRD42018118040.\n",
      "Population: 14,170 participants meeting clinical cut-offs for major depression.\n",
      " , intervention: \n",
      "\n",
      "Intervention: Exercise (specifically walking/jogging, yoga, strength training, mixed aerobic exercises , comparator: \n",
      "\n",
      "Psychotherapy, antidepressants, and control conditions.\n",
      " , outcome: \n",
      "\n",
      "Outcome: Moderate reductions in depression.\n",
      "\n",
      "===== 6 =====\n",
      "Cost and Outcome of Behavioural Activation versus Cognitive Behavioural Therapy for Depression (COBRA): a randomised, controlled, non-inferiority trial\n",
      "National Institute for Health Research.\n",
      "Population: \n",
      "NONE\n",
      " , intervention: \n",
      "NONE\n",
      " , comparator: \n",
      "\n",
      "NONE\n",
      " , outcome: \n",
      "\n",
      "Please provide the study abstract! I need the text of the abstract to be able to extract the\n",
      "===== 7 =====\n",
      "A brief diet intervention can reduce symptoms of depression in young adults – A randomised controlled trial\n",
      "There is strong epidemiological evidence that poor diet is associated with depression. The reverse has also been shown, namely that eating a healthy diet rich in fruit, vegetables, fish and lean meat, is associated with reduced risk of depression. To date, only one randomised controlled trial (RCT) has been conducted with elevated depression symptoms being an inclusion criterion, with results showing that a diet intervention can reduce clinical levels of depression. No such RCTs have been performed in young adults. Young adults with elevated levels of depression symptoms and who habitually consume a poor diet were randomly allocated to a brief 3-week diet intervention (Diet Group) or a habitual diet control group (Control Group). The primary and secondary outcome measures assessed at baseline and after the intervention included symptoms of depression (Centre for Epidemiological Studies Depression Scale; CESD-R; and Depression Anxiety and Stress Scale- 21 depression subscale; DASS-21-D), current mood (Profile of Mood States), self-efficacy (New General Self-Efficacy Scale) and memory (Hopkins Verbal Learning Test). Diet compliance was measured via self-report questionnaires and spectrophotometry. One-hundred-and-one individuals were enrolled in the study and randomly assigned to the Diet Group or the Control Group. Upon completion of the study, there was complete data for 38 individuals in each group. There was good compliance with the diet intervention recommendations assessed using self-report and spectrophotometry. The Diet group had significantly lower self-reported depression symptoms than the Control Group on the CESD-R (p = 0.007, Cohen's d = 0.65) and DASS-21 depression subscale (p = 0.002, Cohen's d = 0.75) controlling for baseline scores on these scales. Reduced DASS-21 depression subscale scores were maintained on follow up phone call 3 months later (p = .009). These results are the first to show that young adults with elevated depression symptoms can engage in and adhere to a diet intervention, and that this can reduce symptoms of depression. The findings provide justification for future research into the duration of these benefits, the impacts of varying diet composition, and their biological basis.\n",
      "Population: \n",
      "Young adults with elevated depression symptoms.\n",
      " , intervention: 3-week diet intervention\n",
      " , comparator: \n",
      "\n",
      "Habitual diet control group.\n",
      " , outcome: \n",
      "\n",
      "Reduced depression symptoms (as measured by CESD-R and DASS-21) in\n",
      "===== 8 =====\n",
      "The impact of whole-of-diet interventions on depression and anxiety: a systematic review of randomised controlled trials\n",
      "Abstract Objective Non-pharmacological approaches to the treatment of depression and anxiety are of increasing importance, with emerging evidence supporting a role for lifestyle factors in the development of these disorders. Observational evidence supports a relationship between habitual diet quality and depression. Less is known about the causative effects of diet on mental health outcomes. Therefore a systematic review was undertaken of randomised controlled trials of dietary interventions that used depression and/or anxiety outcomes and sought to identify characteristics of programme success. Design A systematic search of the Cochrane, MEDLINE, EMBASE, CINAHL, PubMed and PyscInfo databases was conducted for articles published between April 1971 and May 2014. Results Of the 1274 articles identified, seventeen met eligibility criteria and were included. All reported depression outcomes and ten reported anxiety or total mood disturbance. Compared with a control condition, almost half (47 %) of the studies observed significant effects on depression scores in favour of the treatment group. The remaining studies reported a null effect. Effective dietary interventions were based on a single delivery mode, employed a dietitian and were less likely to recommend reducing red meat intake, select leaner meat products or follow a low-cholesterol diet. Conclusions Although there was a high level of heterogeneity, we found some evidence for dietary interventions improving depression outcomes. However, as only one trial specifically investigated the impact of a dietary intervention in individuals with clinical depression, appropriately powered trials that examine the effects of dietary improvement on mental health outcomes in those with clinical disorders are required.\n",
      "Population: \n",
      "Individuals with depression and/or anxiety. , intervention: \n",
      "Dietary interventions.\n",
      " , comparator: \n",
      "\n",
      "Control condition.\n",
      " , outcome: \n",
      "\n",
      "Significant effects on depression scores were observed in almost half (47%) of the studies compared to\n",
      "===== 9 =====\n",
      "Computerised cognitive behaviour therapy (cCBT) as treatment for depression in primary care (REEACT trial): large scale pragmatic randomised controlled trial\n",
      "Commissioned and funded by the UK National Institute for Health Research (NIHR) Health Technology Assessment (HTA) programme (project No 06/43/05). The authors have no competing interests. Requests for patient level data will be considered by the REEACT trial management groupTrial registration Current Controlled Trials ISRCTN91947481.\n",
      "Population: \n",
      "NONE\n",
      " , intervention: \n",
      "NONE\n",
      " , comparator: \n",
      "NONE\n",
      " , outcome: \n",
      "\n",
      "NONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_abstracts): \n",
    "    print(f'===== {i} =====')\n",
    "    print(res_[i]['title'])\n",
    "    print(abstract[i])\n",
    "    if abstract[i]:\n",
    "        population = generateFromPrompt(\"PICO: Please extract the population, if any, mentioned in the following study abstract: \"+abstract[i]+\". Return only the concise answer or 'NONE' if not mentioned. Response: \")\n",
    "        intervention = generateFromPrompt(\"PICO: Please extract the intervention, if any, mentioned in the following study abstract: \"+abstract[i]+\". Return only the concise answer or 'NONE' if not mentioned. Response: \")\n",
    "        comparator = generateFromPrompt(\"PICO: Please extract the comparator, if any, mentioned in the following study abstract: \"+abstract[i]+\". Return only the concise answer or 'NONE' if not mentioned. Response: \")\n",
    "        outcome = generateFromPrompt(\"PICO: Please extract the outcome, if any, mentioned in the following study abstract: \"+abstract[i]+\". Return only the concise answer or 'NONE' if not mentioned. Response: \")\n",
    "        print(\"Population:\",population,\", intervention:\",intervention,\", comparator:\",comparator,\", outcome:\",outcome)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
